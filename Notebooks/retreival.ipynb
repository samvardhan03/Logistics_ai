{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpyQQrh2Jgdz"
      },
      "outputs": [],
      "source": [
        "#hybrid_search.py\n",
        "import logging\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "#Define Pydantic Model for Search Query\n",
        "class SearchQuery(BaseModel):\n",
        "    query_text: str = Field(..., min_length=3, description=\"User query for searching compliance rules\")\n",
        "    top_n: int = Field(default=5, gt=0, description=\"Number of results to return\")\n",
        "\n",
        "#Define Pydantic Model for Search Results\n",
        "class SearchResult(BaseModel):\n",
        "    id: str\n",
        "    score: float\n",
        "\n",
        "class HybridSearch:\n",
        "    \"\"\" Combines BM25 (Keyword Search) + FAISS (Vector Search) for optimized retrieval \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        logging.basicConfig(filename=\"logs/service_logs.log\", level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
        "        self.bm25_search = BM25Search()\n",
        "        self.vector_search = VectorSearch()\n",
        "\n",
        "    def retrieve_documents(self, query: SearchQuery) -> List[SearchResult]:\n",
        "        \"\"\" Hybrid search combining BM25 keyword search and FAISS vector search \"\"\"\n",
        "        try:\n",
        "            #Validate input using Pydantic\n",
        "            query = SearchQuery(**query.dict())\n",
        "\n",
        "            # Run BM25 keyword search\n",
        "            bm25_results = self.bm25_search.search(query.query_text, query.top_n)\n",
        "\n",
        "            # Run Vector search (Semantic Search)\n",
        "            vector_results = self.vector_search.search(query.query_text, query.top_n)\n",
        "\n",
        "            #Combine & Rank Results (BM25 + Vector)\n",
        "            combined_results = self.rank_results(bm25_results, vector_results)\n",
        "            logging.info(f\"Hybrid Search Results: {combined_results}\")\n",
        "\n",
        "            return combined_results\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Hybrid Search Failed: {e}\")\n",
        "            return []\n",
        "\n",
        "    def rank_results(self, bm25_results: List[SearchResult], vector_results: List[SearchResult]) -> List[SearchResult]:\n",
        "        \"\"\" Merges BM25 & Vector Search results using a ranking function \"\"\"\n",
        "        combined = {}\n",
        "\n",
        "        #Merge BM25 & Vector scores\n",
        "        for doc in bm25_results:\n",
        "            combined[doc.id] = combined.get(doc.id, 0) + doc.score * 0.6  # BM25 has 60% weight\n",
        "        for doc in vector_results:\n",
        "            combined[doc.id] = combined.get(doc.id, 0) + doc.score * 0.4  # Vector has 40% weight\n",
        "\n",
        "        # Sort by highest ranking score\n",
        "        sorted_results = sorted(combined.items(), key=lambda x: x[1], reverse=True)\n",
        "        return [SearchResult(id=doc_id, score=score) for doc_id, score in sorted_results]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sMTwXEMwesq",
        "outputId": "9dc7a98a-7f07-4253-f55c-14f6922eb2c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.11/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank_bm25) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#keyword_search.py\n",
        "import logging\n",
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "import rank_bm25\n",
        "\n",
        "\n",
        "# Define Pydantic Model for Compliance Documents\n",
        "class ComplianceDocument(BaseModel):\n",
        "    id: str\n",
        "    text: str\n",
        "\n",
        "# Define Pydantic Model for Search Results\n",
        "class BM25SearchResult(BaseModel):\n",
        "    id: str\n",
        "    score: float\n",
        "\n",
        "class BM25Search:\n",
        "    \"\"\" BM25 Keyword Search for Compliance Documents \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        logging.basicConfig(filename=\"logs/service_logs.log\", level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
        "        self.documents, self.corpus, self.bm25 = self.load_documents()\n",
        "\n",
        "    def load_documents(self) -> List[ComplianceDocument]:\n",
        "        \"\"\" Loads all compliance documents into BM25 search model \"\"\"\n",
        "        try:\n",
        "            documents = [ComplianceDocument(**doc) for doc in get_all_documents()]\n",
        "            corpus = [doc.text.split() for doc in documents]  # Tokenize text\n",
        "            bm25 = rank_bm25.BM25Okapi(corpus)\n",
        "            logging.info(f\"BM25 Index Loaded with {len(documents)} Documents\")\n",
        "            return documents, corpus, bm25\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"BM25 Index Load Failed: {e}\")\n",
        "            return [], [], None\n",
        "\n",
        "    def search(self, query_text: str, top_n: int = 5) -> List[BM25SearchResult]:\n",
        "        \"\"\" Searches BM25 index and returns top matching documents \"\"\"\n",
        "        try:\n",
        "            query_tokens = query_text.split()\n",
        "            scores = self.bm25.get_scores(query_tokens)\n",
        "            ranked_results = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)[:top_n]\n",
        "\n",
        "            return [BM25SearchResult(id=self.documents[i].id, score=score) for i, score in ranked_results]\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"BM25 Search Failed: {e}\")\n",
        "            return []\n"
      ],
      "metadata": {
        "id": "x-2ndw33wHvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6yLkTx61Pzl",
        "outputId": "e80ab7f1-38c7-4646-9562-0ad6cef4155e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "class VectorSearch:\n",
        "    \"\"\" FAISS / ChromaDB-based Semantic Search \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        logging.basicConfig(filename=\"logs/service_logs.log\", level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
        "        self.model = SentenceTransformer(\"all-MiniLM-L6-v2\")  #Lightweight transformer model for embeddings\n",
        "        self.index, self.document_map = self.load_faiss_index()\n",
        "\n",
        "    def load_faiss_index(self):\n",
        "        \"\"\" Loads FAISS Index with Pre-Encoded Compliance Rules \"\"\"\n",
        "        try:\n",
        "            documents = get_all_vectors()\n",
        "            embeddings = np.array([doc[\"vector\"] for doc in documents]).astype(\"float32\")\n",
        "\n",
        "            index = faiss.IndexFlatL2(embeddings.shape[1])  #L2 Distance for Nearest Neighbor Search\n",
        "            index.add(embeddings)\n",
        "\n",
        "            logging.info(f\"FAISS Index Loaded with {len(documents)} Documents\")\n",
        "            return index, {i: doc[\"id\"] for i, doc in enumerate(documents)}\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"FAISS Index Load Failed: {e}\")\n",
        "            return None, {}\n",
        "\n",
        "    def search(self, query_text, top_n=5):\n",
        "        \"\"\" Searches FAISS for Semantic Matches \"\"\"\n",
        "        try:\n",
        "            query_vector = self.model.encode(query_text).astype(\"float32\")\n",
        "            distances, indices = self.index.search(np.array([query_vector]), top_n)\n",
        "\n",
        "            return [{\"id\": self.document_map[i], \"score\": 1 - distances[0][j]} for j, i in enumerate(indices[0])]\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"FAISS Search Failed: {e}\")\n",
        "            return []\n"
      ],
      "metadata": {
        "id": "e6HXfCEhwYqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "accA_Cfq1EN5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}